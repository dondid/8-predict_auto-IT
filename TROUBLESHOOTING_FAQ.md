# ğŸ”§ Troubleshooting & FAQ

## ğŸš¨ Probleme Comune È™i SoluÈ›ii

---

### âŒ Eroare 1: "ModuleNotFoundError: No module named 'X'"

**Descriere**: Python nu gÄƒseÈ™te o librÄƒrie necesarÄƒ

**CauzÄƒ**: LibrÄƒriile nu sunt instalate

**SoluÈ›ie**:
```bash
# InstaleazÄƒ toate librÄƒriile dintr-o datÄƒ
pip install -r requirements.txt

# SAU instaleazÄƒ individual
pip install pandas numpy scikit-learn xgboost matplotlib seaborn shap scipy
```

**Verificare**:
```bash
python test_01_check_installation.py
```

---

### âŒ Eroare 2: "FileNotFoundError: [Errno 2] No such file or directory: 'processed_data.pkl'"

**Descriere**: Scripturile cautÄƒ fiÈ™iere generate de etapele anterioare

**CauzÄƒ**: Nu ai rulat modulele Ã®n ordine

**SoluÈ›ie 1** (RecomandatÄƒ):
```bash
# RuleazÄƒ master pipeline care face totul automat
python 00_master_pipeline.py
```

**SoluÈ›ie 2** (Manual):
```bash
# RuleazÄƒ Ã®n ordine
python 01_data_loading.py
python 02_data_preprocessing.py
python 03_random_forest_model.py
# etc.
```

**Verificare**:
```bash
# VerificÄƒ dacÄƒ fiÈ™ierele existÄƒ
ls *.pkl
```

---

### âŒ Eroare 3: "HTTPError: HTTP Error 404: Not Found" (la Ã®ncÄƒrcarea datelor)

**Descriere**: Dataset-ul nu poate fi descÄƒrcat de la UCI

**CauzÄƒ**: Probleme de conexiune sau URL-ul s-a schimbat

**SoluÈ›ie 1** - DescarcÄƒ manual:
1. AcceseazÄƒ: https://archive.ics.uci.edu/ml/datasets/automobile
2. DescarcÄƒ `imports-85.data`
3. SalveazÄƒ Ã®n folder-ul proiectului
4. ModificÄƒ Ã®n `01_data_loading.py`:
```python
# Ãn loc de URL
# df = pd.read_csv(url, names=column_names, na_values='?')

# FoloseÈ™te fiÈ™ierul local
df = pd.read_csv('imports-85.data', names=column_names, na_values='?')
```

**SoluÈ›ie 2** - VerificÄƒ conexiunea:
```bash
ping archive.ics.uci.edu
```

---

### âŒ Eroare 4: SVR foarte lent / se blocheazÄƒ

**Descriere**: SVR dureazÄƒ foarte mult sÄƒ se antreneze

**CauzÄƒ**: SVR are complexitate O(nÂ²) - O(nÂ³), normal pentru acest algoritm

**SoluÈ›ie 1** - Reduce cross-validation:
Ãn `05_svr_model.py`, linia ~190:
```python
# Ãn loc de 30
cv_results = perform_cross_validation(X_combined, y_combined, n_runs=10)  # Reduce la 10
```

**SoluÈ›ie 2** - Skip hyperparameter tuning:
Ãn `05_svr_model.py`, linia ~70:
```python
svr_model = train_svr(
    data_dict['X_train'], data_dict['y_train'],
    data_dict['X_val'], data_dict['y_val'],
    tune_hyperparams=False  # SeteazÄƒ False
)
```

**SoluÈ›ie 3** - Reduce sample size pentru CV:
```python
# Sample doar 75% din date pentru CV la SVR
X_sample = X_combined.sample(frac=0.75, random_state=42)
y_sample = y_combined[X_sample.index]
```

**Estimare timp**:
- Cu hyperparameter tuning: 20-40 minute
- FÄƒrÄƒ tuning: 5-10 minute
- Cu n_runs=10: 3-5 minute

---

### âŒ Eroare 5: "MemoryError" sau Python crashes

**Descriere**: Python consumÄƒ prea multÄƒ memorie

**CauzÄƒ**: SHAP values sau cross-validation pe date mari

**SoluÈ›ie 1** - Reduce samples pentru SHAP:
Ãn `03_random_forest_model.py`, linia ~270:
```python
shap_values, explainer = compute_shap_values(
    rf_model,
    data_dict['X_train'],
    data_dict['X_test'],
    max_samples=50  # Reduce de la 100 la 50
)
```

**SoluÈ›ie 2** - Reduce cross-validation runs:
```python
cv_results = perform_cross_validation(..., n_runs=10)  # Ãn loc de 30
```

**SoluÈ›ie 3** - Ãnchide alte aplicaÈ›ii:
- Browser-e
- IDE-uri grele
- AplicaÈ›ii Ã®n background

**Verificare memorie disponibilÄƒ**:
```python
import psutil
print(f"RAM disponibil: {psutil.virtual_memory().available / (1024**3):.2f} GB")
```

---

### âŒ Eroare 6: "Convergence Warning" la Neural Network

**Descriere**: 
```
ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
```

**CauzÄƒ**: Neural Network nu a avut destule iteraÈ›ii sÄƒ ajungÄƒ la convergenÈ›Äƒ

**SoluÈ›ie** - CreÈ™te max_iter:
Ãn `06_neural_network_model.py`:
```python
mlp_model = MLPRegressor(
    hidden_layer_sizes=(100, 50, 30),
    activation='relu',
    solver='adam',
    alpha=0.001,
    learning_rate='adaptive',
    max_iter=1000,  # CreÈ™te de la 500 la 1000
    early_stopping=True,
    validation_fraction=0.15,
    random_state=42,
    verbose=False
)
```

**Nu e o problemÄƒ gravÄƒ**: Modelul va funcÈ›iona, doar cÄƒ ar putea avea performanÈ›Äƒ uÈ™or mai slabÄƒ.

---

### âŒ Eroare 7: Plot-urile nu se salveazÄƒ / nu apar

**Descriere**: FiÈ™ierele .png nu sunt generate

**CauzÄƒ**: Matplotlib backend sau permisiuni folder

**SoluÈ›ie 1** - SeteazÄƒ backend explicit:
La Ã®nceputul fiecÄƒrui script cu plots:
```python
import matplotlib
matplotlib.use('Agg')  # Backend non-interactive
import matplotlib.pyplot as plt
```

**SoluÈ›ie 2** - VerificÄƒ permisiuni:
```bash
# Windows
icacls . /grant Users:F

# Linux/Mac
chmod 755 .
```

**SoluÈ›ie 3** - SpecificÄƒ path absolut:
```python
import os
save_path = os.path.join(os.getcwd(), 'rf_predictions.png')
plt.savefig(save_path, dpi=300, bbox_inches='tight')
```

---

### âŒ Eroare 8: "ImportError: cannot import name 'xxx' from 'sklearn'"

**Descriere**: FuncÈ›ii sklearn nu pot fi importate

**CauzÄƒ**: Versiune veche de scikit-learn

**SoluÈ›ie** - Update sklearn:
```bash
pip install --upgrade scikit-learn
```

**Verificare versiune**:
```python
import sklearn
print(sklearn.__version__)  # Trebuie >= 1.2.0
```

---

### âŒ Eroare 9: Cross-validation dureazÄƒ foarte mult

**Descriere**: 30 de runs Ã— 4 modele = foarte mult timp

**CauzÄƒ**: Normal - asta e partea care dureazÄƒ cel mai mult

**SoluÈ›ie 1** - Reduce runs:
```python
# Ãn loc de 30, foloseÈ™te 10
cv_results = perform_cross_validation(..., n_runs=10)
```

**SoluÈ›ie 2** - Paralelizare (advanced):
```python
from joblib import Parallel, delayed

def single_cv_run(X, y, model, seed):
    # ... logica pentru un run
    return mse, rmse, r2

results = Parallel(n_jobs=-1)(
    delayed(single_cv_run)(X, y, model, i) 
    for i in range(30)
)
```

**Estimare timp totalÄƒ**:
- Quick test (reduced settings): 2-3 minute
- Pipeline complet cu tune_hyperparams=False: 15-20 minute
- Pipeline complet cu tune_hyperparams=True: 30-45 minute

---

### âŒ Eroare 10: "ValueError: could not convert string to float"

**Descriere**: Date nu pot fi convertite la numeric

**CauzÄƒ**: Encoding incomplet pentru variabile categoriale

**Verificare**:
```python
# VerificÄƒ tipurile de date
print(X_train.dtypes)
print(X_train.select_dtypes(include=['object']).columns)
```

**SoluÈ›ie** - AsigurÄƒ-te cÄƒ toate coloanele sunt numerice dupÄƒ encoding:
Ãn `02_data_preprocessing.py`, adaugÄƒ:
```python
# DupÄƒ encoding
print("Columns still object type:", X.select_dtypes(include=['object']).columns.tolist())

# ForÈ›eazÄƒ conversie
for col in X.select_dtypes(include=['object']).columns:
    X[col] = pd.to_numeric(X[col], errors='coerce')
    X[col].fillna(X[col].median(), inplace=True)
```

---

### âŒ Eroare 11: "Streamlit command not found"

**Descriere**: Nu poÈ›i rula `streamlit run dashboard.py`

**CauzÄƒ**: `streamlit` nu e Ã®n PATH sau e instalat Ã®n alt venv

**SoluÈ›ie**:
```bash
python -m streamlit run dashboard.py
```
Sau reinstaleazÄƒ: `pip install streamlit`

---

### âŒ Eroare 12: "Gemini API Key Missing"

**Descriere**: AI Assistant nu rÄƒspunde / apare eroare 403

**CauzÄƒ**: Cheia API nu e setatÄƒ Ã®n `.env`

**SoluÈ›ie**:
1. CreeazÄƒ fiÈ™ier `.env` (copiazÄƒ din `.env.example`)
2. AdaugÄƒ linia: `GEMINI_API_KEY=AIzaSy...` (cheia ta realÄƒ)
3. Restart la aplicaÈ›ie

---

## ğŸ¯ ÃntrebÄƒri Frecvente (FAQ)

### Q1: CÃ¢t timp dureazÄƒ sÄƒ rulez tot proiectul?

**A**: 
- **Quick test** (test_02_quick_pipeline.py): 2-3 minute
- **Pipeline complet** (fÄƒrÄƒ hyperparameter tuning): 15-20 minute
- **Pipeline complet** (cu hyperparameter tuning): 30-45 minute
- **SVR cu tuning**: +20-30 minute

**Recomandare**: RuleazÄƒ fÄƒrÄƒ tuning pentru test, apoi cu tuning pentru rezultate finale.

---

### Q2: Care model este de obicei cel mai bun?

**A**: Pe acest dataset, de obicei:
1. **XGBoost** - 85-92% RÂ²
2. **Random Forest** - 83-90% RÂ²
3. **Neural Network** - 80-89% RÂ²
4. **SVR** - 78-88% RÂ²

Dar poate varia Ã®n funcÈ›ie de split-ul aleatoriu!

---

### Q3: Pot schimba dataset-ul?

**A**: Da! PaÈ™ii:

1. **GÄƒseÈ™te un dataset de regresie** (ex: Kaggle, UCI)
2. **ModificÄƒ Ã®n `01_data_loading.py`**:
   - URL/path cÄƒtre dataset
   - `column_names`
   - Numele coloanei È›intÄƒ (Ã®n loc de `price`)
3. **AjusteazÄƒ preprocessing Ã®n `02_data_preprocessing.py`**:
   - Logica pentru missing values
   - Feature engineering specific domeniului
4. **RuleazÄƒ restul scripturilor normal**

**Sugestii dataset**:
- California Housing
- Boston Housing (similar cu automobile)
- Diamond Prices
- Insurance Costs

---

### Q4: Cum adaug un al 5-lea model?

**A**: 

1. **CreeazÄƒ `08_new_model.py`** copiat din unul existent
2. **ModificÄƒ modelul**:
```python
from sklearn.linear_model import Ridge  # Exemplu

def train_new_model(X_train, y_train, X_val, y_val):
    model = Ridge(alpha=1.0)
    model.fit(X_train, y_train)
    return model
```
3. **SalveazÄƒ rezultatele** similar cu celelalte:
```python
with open('new_model_results.pkl', 'wb') as f:
    pickle.dump(results_summary, f)
```
4. **ActualizeazÄƒ `07_model_comparison_statistical.py`**:
```python
model_files = {
    # ... modelele existente
    'New Model': 'new_model_results.pkl'
}
```

---

### Q5: Cum exportez rezultatele Ã®ntr-un format mai user-friendly?

**A**:

**Excel**:
```python
# Ãn 07_model_comparison_statistical.py
comparison_df.to_excel('model_comparison.xlsx', index=True)
```

**HTML**:
```python
html = comparison_df.to_html()
with open('results.html', 'w') as f:
    f.write(html)
```

**LaTeX** (pentru rapoarte academice):
```python
latex = comparison_df.to_latex()
with open('results.tex', 'w') as f:
    f.write(latex)
```

---

### Q6: Pot rula pe Google Colab?

**A**: Da!

**PaÈ™i**:
1. Upload toate fiÈ™ierele .py Ã®n Colab
2. InstaleazÄƒ dependencies:
```python
!pip install -r requirements.txt
```
3. RuleazÄƒ:
```python
!python 00_master_pipeline.py
```
4. Download rezultatele:
```python
from google.colab import files

# Download toate PNG-urile
import glob
for file in glob.glob("*.png"):
    files.download(file)
```

**Avantaj**: Hardware mai puternic, GPU gratuit

---

### Q7: Cum verific cÄƒ rezultatele mele sunt corecte/rezonabile?

**A**:

**Checklist validare**:
- [ ] RÂ² Ã®ntre 0.7-0.95 (pentru majoritatea modelelor)
- [ ] RMSE Ã®n intervalul 2000-5000 (pentru preÈ›uri automobile)
- [ ] MAE < RMSE (Ã®ntotdeauna adevÄƒrat matematic)
- [ ] Training RÂ² > Test RÂ² (uÈ™oarÄƒ diferenÈ›Äƒ e normalÄƒ)
- [ ] DiferenÈ›a Train-Test RÂ² < 0.10 (altfel: overfitting)
- [ ] Cross-validation std rezonabilÄƒ (< 20% din mean)

**Red flags**:
- âŒ RÂ² = 1.0 sau foarte aproape â†’ Data leakage suspect
- âŒ RÂ² negativ â†’ Model mai rÄƒu decÃ¢t media
- âŒ RMSE > 10,000 â†’ Ceva e foarte greÈ™it
- âŒ Train RÂ² = 0.99, Test RÂ² = 0.50 â†’ Overfitting sever

---

### Q8: Ce fac dacÄƒ Wilcoxon test aratÄƒ p > 0.05 pentru toate comparaÈ›iile?

**A**: 

**ÃnseamnÄƒ**: Nu existÄƒ diferenÈ›e statistice semnificative Ã®ntre modele.

**E OK!** PoÈ›i spune:
> "DeÈ™i [Model X] are cea mai bunÄƒ performanÈ›Äƒ medie (RÂ²=0.XX), testele Wilcoxon indicÄƒ cÄƒ diferenÈ›ele nu sunt statistic semnificative (toate p > 0.05). Aceasta sugereazÄƒ cÄƒ toate cele 4 modele au performanÈ›e comparabile pe acest dataset. Ãn practicÄƒ, am alege [Model X] datoritÄƒ [uÈ™urinÈ›ei interpretÄƒrii / vitezei de execuÈ›ie / etc.]"

**Nu e o problemÄƒ** - aratÄƒ cÄƒ ai analizat corect!

---

### Q9: Plot-urile nu aratÄƒ bine Ã®n PowerPoint. Ce fac?

**A**:

**SoluÈ›ie 1** - CreÈ™te DPI la salvare:
```python
plt.savefig('plot.png', dpi=600, bbox_inches='tight')  # Dublu faÈ›Äƒ de 300
```

**SoluÈ›ie 2** - SalveazÄƒ ca SVG (vector):
```python
plt.savefig('plot.svg', format='svg', bbox_inches='tight')
```
Apoi Ã®n PowerPoint: Insert â†’ Pictures â†’ SVG

**SoluÈ›ie 3** - AjusteazÄƒ size Ã®n Python:
```python
fig, ax = plt.subplots(figsize=(12, 8))  # Mai mare
plt.savefig('plot.png', dpi=300, bbox_inches='tight')
```

---

### Q10: Cum explic rezultatele la cineva non-tehnic?

**A**:

**Template simplu**:

**RÂ² Score**:
> "RÂ² ne spune ce procent din variaÈ›ia preÈ›ului e explicatÄƒ de model. Un RÂ² de 0.85 Ã®nseamnÄƒ cÄƒ modelul explicÄƒ 85% din diferenÈ›ele de preÈ› Ã®ntre maÈ™ini."

**RMSE**:
> "RMSE e eroarea medie Ã®n dolari. Un RMSE de 3000$ Ã®nseamnÄƒ cÄƒ, Ã®n medie, predicÈ›iile diferÄƒ cu Â±3000$ faÈ›Äƒ de preÈ›ul real."

**Wilcoxon Test**:
> "E ca un test statistic care ne spune dacÄƒ diferenÈ›a Ã®ntre douÄƒ modele e realÄƒ sau doar Ã®ntÃ¢mplÄƒtoare. DacÄƒ p < 0.05, diferenÈ›a e semnificativÄƒ."

**Feature Importance**:
> "Ne aratÄƒ care caracteristici ale maÈ™inii conteazÄƒ cel mai mult pentru preÈ›. De exemplu, dimensiunea motorului È™i puterea sunt cei mai importanÈ›i factori."

---

## ğŸ“ Support È™i Resurse

### DacÄƒ tot nu merge:

1. **VerificÄƒ log-urile**:
```bash
python 00_master_pipeline.py 2>&1 | tee pipeline_log.txt
```

2. **PosteazÄƒ pe forum**:
   - Stack Overflow
   - Reddit r/learnmachinelearning
   - Grupul de curs

3. **DocumentaÈ›ie oficialÄƒ**:
   - [Scikit-learn](https://scikit-learn.org/)
   - [XGBoost](https://xgboost.readthedocs.io/)
   - [Pandas](https://pandas.pydata.org/)

4. **ContacteazÄƒ profesorul**:
   - Email cu log-uri È™i screenshot-uri
   - Descrie paÈ™ii urmaÈ›i

---

**Remember**: Majoritatea erorilor sunt uÈ™or de rezolvat - nu te panica! ğŸ’ª**